{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一部分：将 FullIJCNN2013 数据集转换成 yolo3格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1【可选】、打印所有交通标记的信息，例如【单向行驶标记】有多少个图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 3:\n",
      "          img   x1   y1    x2   y2  id\n",
      "0  00000.ppm  774  411   815  446  11\n",
      "1  00001.ppm  983  388  1024  432  40\n",
      "2  00001.ppm  386  494   442  552  38\n",
      "the top 3 id:\n",
      " 0    11\n",
      "1    40\n",
      "2    38\n",
      "Name: id, dtype: int64\n",
      "Train has image files with traffic signs numbers: 741\n",
      "Train has traffic signs class numbers: 43\n",
      "Train has traffic signs instance numbers: 1213\n",
      "38    88\n",
      "12    85\n",
      "13    83\n",
      "2     81\n",
      "10    80\n",
      "1     79\n",
      "4     68\n",
      "8     57\n",
      "5     53\n",
      "9     41\n",
      "7     41\n",
      "11    38\n",
      "18    38\n",
      "14    32\n",
      "25    31\n",
      "3     30\n",
      "17    29\n",
      "23    20\n",
      "35    20\n",
      "6     19\n",
      "26    18\n",
      "30    16\n",
      "33    16\n",
      "15    15\n",
      "28    14\n",
      "22    13\n",
      "34    12\n",
      "42    11\n",
      "40    10\n",
      "20     9\n",
      "36     9\n",
      "32     8\n",
      "16     8\n",
      "41     7\n",
      "39     6\n",
      "21     5\n",
      "24     5\n",
      "29     5\n",
      "0      4\n",
      "27     3\n",
      "19     2\n",
      "31     2\n",
      "37     2\n",
      "Name: id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "FullIJCNN2013_path = \"/home/wilson/workstation/my_traffic_tf2/data/FullIJCNN2013\"\n",
    "data = pd.read_csv(FullIJCNN2013_path+ \"/gt.txt\", sep=\";\", header=None)\n",
    "data.columns = [\"img\", \"x1\", \"y1\", \"x2\", \"y2\", \"id\"]\n",
    "\n",
    "top3 = data[:3]\n",
    "print(\"the top 3:\\n\", top3)\n",
    "print(\"the top 3 id:\\n\", top3['id'])\n",
    "\n",
    "# 741 张图片， 每张图片属于多个分类\n",
    "print(\"Train has image files with traffic signs numbers:\", len(data['img'].unique())) \n",
    "\n",
    "# 43 个分类\n",
    "print(\"Train has traffic signs class numbers:\", len(data['id'].unique()))\n",
    "\n",
    "# 总共1213 条记录\n",
    "print(\"Train has traffic signs instance numbers:\", data['id'].count())\n",
    "\n",
    "#pd.value_counts(data['id'], sort=False).plot.bar()\n",
    "#打印每个分类的个数\n",
    "print(pd.value_counts(data['id'], sort=True))\n",
    "data['id'].hist(bins=86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2、导出yolo使用的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 3:\n",
      "          img   x1   y1    x2   y2  id\n",
      "0  00000.ppm  774  411   815  446  11\n",
      "1  00001.ppm  983  388  1024  432  40\n",
      "2  00001.ppm  386  494   442  552  38\n",
      "\n",
      "shuffles count: 1213\n",
      "\n",
      "train count: 849\n",
      " test count: 364\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [00:08<00:00, 59.89it/s]\n",
      "100%|██████████| 238/238 [00:03<00:00, 75.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "FullIJCNN2013 的数据集格式 gt.txt:\n",
    "img;x1;y1;x2;y2;id\n",
    "\n",
    "--------\n",
    "\n",
    "yolo3 的数据集所需格式 FullIJCNN2013.dataset:\n",
    "xxx/xxx.jpg 18.19,6.32,424.13,421.83,20 323.86,2.65,640.0,421.94,20 \n",
    "xxx/xxx.jpg 48,240,195,371,11 8,12,352,498,14\n",
    "image_path x_min,y_min,x_max,y_max,class_id  x_min,y_min,...,class_id \n",
    "(注意空格和逗号)\n",
    "\"\"\"\n",
    "\n",
    "# 需要预处理三大部分内容：\n",
    "# 1、训练所需要的图片集合：YOLO3_jpg_dir\n",
    "# 2、每张图片对应的 类别和框框列表：YOLO3_dataset_path\n",
    "# 3、类别映射的名称列表\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 分三种224*224,416*416，608*608三种。图片越大，时间越长，但是并不是resize耗费的时间比较长，是卷积的次数多。\n",
    "TARGET_SIZE = 416\n",
    "\n",
    "# 导出的数据集格式输出位置\n",
    "YOLO3_dataset_train_path = \"./data/dataset/FullIJCNN2013-train.dataset\"\n",
    "YOLO3_dataset_test_path = \"./data/dataset/FullIJCNN2013-test.dataset\"\n",
    "YOLO3_jpg_dir = \"./data/jpgFullIJCNN2013\"\n",
    "YOLO3_classnames_path = \"./data/classes/FullIJCNN2013.names\"\n",
    "\n",
    "FullIJCNN2013_label_path = \"/home/wilson/workstation/my_traffic_tf2/data/gtsdb.label\"\n",
    "FullIJCNN2013_path = \"/home/wilson/workstation/my_traffic_tf2/data/FullIJCNN2013\"\n",
    "PPM_IMG_dir = FullIJCNN2013_path\n",
    "\n",
    "# 数据集输入的jpg图片所在目录\n",
    "if not os.path.exists(YOLO3_jpg_dir):\n",
    "    os.mkdir(YOLO3_jpg_dir)\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['img', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(img, gb.get_group(x)) for img, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "#####################################\n",
    "# 转换输入的图片集合\n",
    "def save_ppm_as_jpg(ppmFilename, jpgFilepath):\n",
    "    ppm_img_path = os.path.join(PPM_IMG_dir, ppmFilename)\n",
    "    with tf.io.gfile.GFile(ppm_img_path, \"rb\") as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        image = image.resize((TARGET_SIZE, TARGET_SIZE),Image.BILINEAR)\n",
    "        image.save(jpgFilepath)\n",
    "\n",
    "########################################\n",
    "# 存储 每张图片对应的 类别和框框列表\n",
    "def save_img_dataset(group, jpgFilepath, dataset_path):   \n",
    "    ppm_img_path = os.path.join(PPM_IMG_dir, group.img)\n",
    "    with tf.io.gfile.GFile(ppm_img_path, \"rb\") as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        originalWidth = image.size[0]\n",
    "        originalHeight = image.size[1]\n",
    "        widthScale = TARGET_SIZE * 1.0 / originalWidth\n",
    "        heightScale = TARGET_SIZE * 1.0 / originalHeight\n",
    "        \n",
    "    with open(dataset_path,\"a\") as file:   #”w\"代表着每次运行都覆盖内容\n",
    "        groupIds = []\n",
    "        groupIds.append(jpgFilepath)\n",
    "        for index, row in group.object.iterrows():\n",
    "            boxIdBlock = []\n",
    "            boxIdBlock.append(str(int(row[\"x1\"] * widthScale)))\n",
    "            boxIdBlock.append(str(int(row[\"y1\"] * heightScale)))\n",
    "            boxIdBlock.append(str(int(row[\"x2\"] * widthScale)))\n",
    "            boxIdBlock.append(str(int(row[\"y2\"] * heightScale)))\n",
    "            boxIdBlock.append(str(int(row[\"id\"])))\n",
    "            groupIds.append(\",\".join(boxIdBlock))\n",
    "        line = \" \".join(groupIds)+\"\\n\"\n",
    "        file.write(line)\n",
    "\n",
    "######################################\n",
    "# 清空数据集文件\n",
    "def clearDatasetFile():\n",
    "    for dataset_path in [YOLO3_dataset_train_path, YOLO3_dataset_test_path]:\n",
    "        with open(dataset_path, \"w\") as file:   #”w\"代表着每次运行都覆盖内容\n",
    "            file.seek(0)\n",
    "            file.truncate()\n",
    "\n",
    "# 转存类别名称\n",
    "def save_labels():\n",
    "    with open(YOLO3_classnames_path, 'w', encoding=\"utf-8\") as fwriter:\n",
    "        with open(FullIJCNN2013_label_path, 'r', encoding=\"utf-8\") as freader:\n",
    "            lines = freader.readlines()\n",
    "            for line in lines:\n",
    "                if not line.split():\n",
    "                    continue\n",
    "                line = line.strip()\n",
    "                _, name = line.split(' ', 1)\n",
    "                fwriter.write(name+\"\\n\")\n",
    "                \n",
    "###################################\n",
    "# 按照图片名进行进行打组\n",
    "def process(df, dataset_path):\n",
    "    groupedByImg = split(df, \"img\")\n",
    "    for group in tqdm(groupedByImg):\n",
    "        jpgFilename = group.img[:-3] + 'jpg'\n",
    "        jpgFilepath = os.path.join(YOLO3_jpg_dir, jpgFilename)\n",
    "        \n",
    "        # 将原始的ppm图片转为 jpg格式并存档\n",
    "        save_ppm_as_jpg(group.img, jpgFilepath)\n",
    "        \n",
    "        # 存储 每张图片对应的 类别和框框列表\n",
    "        save_img_dataset(group, jpgFilepath, dataset_path)\n",
    "\n",
    "#######################################\n",
    "clearDatasetFile()\n",
    "save_labels()\n",
    "\n",
    "data = pd.read_csv(FullIJCNN2013_path+ \"/gt.txt\", sep=\";\", header=None)\n",
    "data.columns = [\"img\", \"x1\", \"y1\", \"x2\", \"y2\", \"id\"]\n",
    "\n",
    "top3 = data[:3]\n",
    "print(\"the top 3:\\n\", top3)\n",
    "\n",
    "# 将分类只有一条记录的数据，拼接到尾部\n",
    "threshold = 1\n",
    "y_less = data.groupby(\"id\").filter(lambda x: len(x) <= threshold)\n",
    "data = pd.concat([data, y_less], ignore_index=True)\n",
    "\n",
    "# 类型对应所有数量\n",
    "idValueList = data['id']\n",
    "#print('\\nid value list:\\n', idValueList)\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "#print('\\nthe kf is:\\n', kf)\n",
    "\n",
    "shuffles = np.hstack((next(kf.split(idValueList))))\n",
    "print(\"\\nshuffles count:\", len(shuffles))\n",
    "\n",
    "train_ratio = 0.7\n",
    "train_count = int(idValueList.count() * train_ratio)\n",
    "test_count = idValueList.count() - train_count\n",
    "print(\"\\ntrain count:\", train_count)\n",
    "print(  \" test count:\", test_count)\n",
    "\n",
    "xtrain, xtest = data.iloc[0:train_count,:], data.iloc[train_count:,:]\n",
    "\n",
    "plt.hist([\n",
    "        xtrain['id'], \n",
    "        xtest['id'], \n",
    "        ], \n",
    "        stacked=True, \n",
    "        label=[\"train\", \"test\"],\n",
    "        bins=86\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "process(xtrain, YOLO3_dataset_train_path)\n",
    "process(xtest, YOLO3_dataset_test_path)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分：使用 SavedModel 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/17_23/variables/variables\n",
      "###-1 <class 'tensorflow.python.framework.ops.Tensor'> Tensor(\"import/input/input_data:0\", dtype=float32)\n",
      "###-2 <class 'tensorflow.python.framework.ops.Tensor'> Tensor(\"import/pred_mbbox/concat_2:0\", shape=(?, ?, ?, 3, 48), dtype=float32)\n",
      "original_image_size: (416, 416)\n",
      "input_size: 416\n",
      "pred-id: 13\n",
      "pred-id: 38\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import core.utils as utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# signature_key = tf.compat.v1.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "signature_key = \"predict_image\"\n",
    "\n",
    "num_classes = 43\n",
    "input_size = 416\n",
    "\n",
    "# 输入的测试图片\n",
    "image_path = \"./docs/images/00013_416x416.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "original_image_size = original_image.shape[:2]\n",
    "image_data = utils.image_preporcess(np.copy(original_image), [input_size, input_size])\n",
    "image_data = image_data[np.newaxis, ...]\n",
    "\n",
    "with tf.compat.v1.Session(graph = tf.Graph()) as sess:\n",
    "    meta_graph_def = tf.compat.v1.saved_model.loader.load(sess, [tf.compat.v1.saved_model.tag_constants.SERVING], \"./models/17_23/\")\n",
    "    signature = meta_graph_def.signature_def\n",
    "    # print(\"signature=======\", signature)\n",
    "    input_tensor_name = signature[signature_key].inputs[\"image\"].name\n",
    "    pred_sbbox_tensor_name = signature[signature_key].outputs[\"pred_mbbox\"].name\n",
    "    pred_mbbox_tensor_name = signature[signature_key].outputs[\"pred_mbbox\"].name\n",
    "    pred_lbbox_tensor_name = signature[signature_key].outputs[\"pred_lbbox\"].name\n",
    "    \n",
    "    #input_tensor = tf.compat.v1.saved_model.utils.build_tensor_info(input_tensor_info)\n",
    "    input_tensor = sess.graph.get_tensor_by_name(input_tensor_name)\n",
    "    pred_sbbox_tensor = sess.graph.get_tensor_by_name(pred_sbbox_tensor_name)\n",
    "    pred_mbbox_tensor = sess.graph.get_tensor_by_name(pred_mbbox_tensor_name)\n",
    "    pred_lbbox_tensor = sess.graph.get_tensor_by_name(pred_lbbox_tensor_name)\n",
    "    \n",
    "    print(\"###-1\", type(input_tensor), input_tensor)\n",
    "    print(\"###-2\", type(pred_sbbox_tensor), pred_sbbox_tensor)\n",
    "    \n",
    "    y = [pred_sbbox_tensor, pred_mbbox_tensor, pred_lbbox_tensor]\n",
    "    #y = [\"pred_sbbox/import/output/pred_sbbox/concat_2:0\",\n",
    "    #    \"pred_mbbox/import/output/pred_mbbox/concat_2:0\",\n",
    "    #    \"pred_lbbox/import/output/pred_lbbox/concat_2:0\"]\n",
    "    feed_dict={\"import/input/input_data:0\":image_data}\n",
    "    pred_sbbox, pred_mbbox, pred_lbbox = sess.run(y, feed_dict=feed_dict)\n",
    "    pred_bbox = np.concatenate([np.reshape(pred_sbbox, (-1, 5 + num_classes)),\n",
    "                             np.reshape(pred_mbbox, (-1, 5 + num_classes)),\n",
    "                             np.reshape(pred_lbbox, (-1, 5 + num_classes))], axis=0)\n",
    "    \n",
    "    print(\"original_image_size:\", original_image_size)\n",
    "    print(\"input_size:\", input_size)\n",
    "    #print(\"pred_bbox:\", pred_bbox)\n",
    "    bboxes = utils.postprocess_boxes(pred_bbox, original_image_size, input_size, 0.09)\n",
    "    bboxes = utils.nms(bboxes, 0.45, method='nms')\n",
    "    \n",
    "    resized_width = 1380\n",
    "    resized_height = 800\n",
    "    resized_image = cv2.resize(original_image,(resized_width, resized_height),interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    width_scale = resized_width * 1.0 / input_size\n",
    "    height_scale = resized_height * 1.0 / input_size\n",
    "    \n",
    "    resized_bboxes = []\n",
    "    for box in bboxes:\n",
    "        x1 = int(box[0]*width_scale)\n",
    "        y1 = int(box[1]*height_scale)\n",
    "        x2 = int(box[2]*width_scale)\n",
    "        y2 = int(box[3]*height_scale)\n",
    "        color = int(box[4])\n",
    "        id = int(box[5])\n",
    "        resized_bboxes.append([x1, y1, x2, y2, color, id])\n",
    "        print(\"pred-id:\", id)\n",
    "    image = utils.draw_bbox(resized_image, resized_bboxes)\n",
    "    image = Image.fromarray(image)\n",
    "    image.show()\n",
    "\n",
    "\n",
    "#with tf.compat.v1.Session() as sess:\n",
    "#    saver = tf.compat.v1.train.import_meta_graph(\"./models/3.1943-10/my_traffic_signal.meta\")\n",
    "#    saver.restore(sess, \"./models/3.1943-10/my_traffic_signal\")\n",
    "#    graph = tf.compat.v1.get_default_graph()\n",
    "#    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "#    #print(tf.compat.v1.all_variables())\n",
    "#    for v in tf.compat.v1.global_variables():\n",
    "#        print(type(v), v)\n",
    "#    X = graph.get_tensor_by_name(\"input/input_data:0\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
